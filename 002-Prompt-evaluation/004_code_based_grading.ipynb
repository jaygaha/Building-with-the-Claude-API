{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905bc712",
   "metadata": {},
   "source": [
    "# Code based grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-haiku-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_messages(messages, text, role=\"user\"):\n",
    "    message = {\"role\": role, \"content\": text}\n",
    "    messages.append(message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, prompt, role=\"user\")\n",
    "    add_messages(messages, \"```json\", role=\"assistant\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset_code.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, eval_prompt, role=\"user\")\n",
    "    add_messages(messages, \"```json\", role=\"assistant\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83809a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\n",
    "* Respond only with Python, JSON, or a plain Regex\n",
    "* Do not add any comments or commentary or explanation\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, prompt, role=\"user\")\n",
    "    add_messages(messages, \"```code\", role=\"assistant\")\n",
    "    output = chat(messages, stop_sequences=[\"```\"])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7953c666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to validate the output structure\n",
    "import re\n",
    "import ast\n",
    "\n",
    "\n",
    "def validate_json(text):\n",
    "    try:\n",
    "        json.loads(text.strip())\n",
    "        return 10\n",
    "    except json.JSONDecodeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_python(text):\n",
    "    try:\n",
    "        ast.parse(text.strip())\n",
    "        return 10\n",
    "    except SyntaxError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def validate_regex(text):\n",
    "    try:\n",
    "        re.compile(text.strip())\n",
    "        return 10\n",
    "    except re.error:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def grade_syntax(response, test_case):\n",
    "    format = test_case[\"format\"]\n",
    "    if format == \"json\":\n",
    "        return validate_json(response)\n",
    "    elif format == \"python\":\n",
    "        return validate_python(response)\n",
    "    else:\n",
    "        return validate_regex(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9bcc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    model_score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    syntax_score = grade_syntax(output, test_case)\n",
    "\n",
    "    score = (model_score + syntax_score) / 2\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fa99d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30fae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 8.166666666666666\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset_code.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbcc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"\\nimport re\\n\\ndef parse_s3_bucket(uri):\\n    match = re.match(r's3://([a-z0-9.-]+)/', uri)\\n    return match.group(1) if match else None\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Parse an AWS S3 bucket name from an S3 URI string (e.g., 's3://my-bucket/path/to/file.txt')\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 7.5,\n",
      "    \"reasoning\": \"The solution demonstrates understanding of the core problem but has practical limitations. The regex character class excludes valid bucket name characters (uppercase letters, underscores) per AWS naming rules. The mandatory trailing slash requirement is overly strict since S3 URIs representing bucket roots are valid without paths. Additionally, the function lacks defensive programming for edge cases like None or non-string inputs, which could cause AttributeError exceptions.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"\\n{\\n  \\\"AWSTemplateFormatVersion\\\": \\\"2010-09-09\\\",\\n  \\\"Description\\\": \\\"CloudFormation template for basic EC2 security group allowing HTTP and HTTPS traffic\\\",\\n  \\\"Resources\\\": {\\n    \\\"BasicSecurityGroup\\\": {\\n      \\\"Type\\\": \\\"AWS::EC2::SecurityGroup\\\",\\n      \\\"Properties\\\": {\\n        \\\"GroupDescription\\\": \\\"Security group allowing HTTP and HTTPS traffic\\\",\\n        \\\"SecurityGroupIngress\\\": [\\n          {\\n            \\\"IpProtocol\\\": \\\"tcp\\\",\\n            \\\"FromPort\\\": 80,\\n            \\\"ToPort\\\": 80,\\n            \\\"CidrIp\\\": \\\"0.0.0.0/0\\\"\\n          },\\n          {\\n            \\\"IpProtocol\\\": \\\"tcp\\\",\\n            \\\"FromPort\\\": 443,\\n            \\\"ToPort\\\": 443,\\n            \\\"CidrIp\\\": \\\"0.0.0.0/0\\\"\\n          }\\n        ]\\n      }\\n    }\\n  },\\n  \\\"Outputs\\\": {\\n    \\\"SecurityGroupId\\\": {\\n      \\\"Description\\\": \\\"Security Group ID\\\",\\n      \\\"Value\\\": {\\n        \\\"Ref\\\": \\\"BasicSecurityGroup\\\"\\n      }\\n    }\\n  }\\n}\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a CloudFormation template JSON object that defines a basic EC2 security group allowing HTTP and HTTPS traffic\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 8.5,\n",
      "    \"reasoning\": \"The template successfully meets the basic requirements by creating a functional security group with HTTP and HTTPS ingress rules using correct syntax. However, it lacks production-readiness considerations such as explicit VPC binding and egress rule definition. The broad CIDR range (0.0.0.0/0) is appropriate for public-facing web services but should be documented. The solution works for a simple use case but could be enhanced with better practices.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"\\nimport re\\n\\ndef extract_service_name(arn: str) -> str:\\n    pattern = r'^arn:aws:([a-z0-9-]+):'\\n    match = re.search(pattern, arn)\\n    if match:\\n        return match.group(1)\\n    return \\\"\\\"\\n\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an AWS IAM ARN string and returns the service name (e.g., 'iam', 's3', 'lambda')\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 8.5,\n",
      "    \"reasoning\": \"The solution correctly solves the core task with a clean, readable regex approach. However, it lacks robustness for production use. The function would benefit from docstring documentation and more explicit error handling. The regex pattern itself is sound for the standard AWS ARN format (arn:aws:service-name:region:account-id:resource), and the type hints are appropriate. The main limitation is the lack of input validation and documentation.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
