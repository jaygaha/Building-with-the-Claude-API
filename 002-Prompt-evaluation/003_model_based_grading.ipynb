{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4560f33",
   "metadata": {},
   "source": [
    "# Model based grading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5437be1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load env variables and create client\n",
    "from dotenv import load_dotenv\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-haiku-4-5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b0d8e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def add_messages(messages, text, role=\"user\"):\n",
    "    message = {\"role\": role, \"content\": text}\n",
    "    messages.append(message)\n",
    "\n",
    "\n",
    "def chat(messages, system=None, temperature=1.0, stop_sequences=[]):\n",
    "    params = {\n",
    "        \"model\": model,\n",
    "        \"max_tokens\": 1000,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": temperature,\n",
    "        \"stop_sequences\": stop_sequences,\n",
    "    }\n",
    "\n",
    "    if system:\n",
    "        params[\"system\"] = system\n",
    "\n",
    "    message = client.messages.create(**params)\n",
    "    return message.content[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e788701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a new dataset\n",
    "import json\n",
    "\n",
    "\n",
    "def generate_dataset():\n",
    "    prompt = \"\"\"\n",
    "Generate a evaluation dataset for a prompt evaluation. The dataset will be used to evaluate prompts\n",
    "that generate Python, JSON, or Regex specifically for AWS-related tasks. Generate an array of JSON objects,\n",
    "each representing task that requires Python, JSON, or a Regex to complete.\n",
    "\n",
    "Example output:\n",
    "```json\n",
    "[\n",
    "    {\n",
    "        \"task\": \"Description of task\",\n",
    "        \"format\": \"json\" or \"python\" or \"regex\"\n",
    "    },\n",
    "    ...additional\n",
    "]\n",
    "```\n",
    "\n",
    "* Focus on tasks that can be solved by writing a single Python function, a single JSON object, or a regular expression.\n",
    "* Focus on tasks that do not require writing much code\n",
    "\n",
    "Please generate 3 objects.\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, prompt, role=\"user\")\n",
    "    add_messages(messages, \"```json\", role=\"assistant\")\n",
    "    text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438ed743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the dataset and write it to 'dataset.json'\n",
    "dataset = generate_dataset()\n",
    "with open(\"dataset.json\", \"w\") as f:\n",
    "    json.dump(dataset, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36b89174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to grade a test case + output using a model\n",
    "def grade_by_model(test_case, output):\n",
    "    eval_prompt = f\"\"\"\n",
    "You are an expert AWS code reviewer. Your task is to evaluate the following AI-generated solution.\n",
    "\n",
    "Original Task:\n",
    "<task>\n",
    "{test_case[\"task\"]}\n",
    "</task>\n",
    "\n",
    "Solution to Evaluate:\n",
    "<solution>\n",
    "{output}\n",
    "</solution>\n",
    "\n",
    "Output Format\n",
    "Provide your evaluation as a structured JSON object with the following fields, in this specific order:\n",
    "- \"strengths\": An array of 1-3 key strengths\n",
    "- \"weaknesses\": An array of 1-3 key areas for improvement\n",
    "- \"reasoning\": A concise explanation of your overall assessment\n",
    "- \"score\": A number between 1-10\n",
    "\n",
    "Respond with JSON. Keep your response concise and direct.\n",
    "Example response shape:\n",
    "{{\n",
    "    \"strengths\": string[],\n",
    "    \"weaknesses\": string[],\n",
    "    \"reasoning\": string,\n",
    "    \"score\": number\n",
    "}}\n",
    "    \"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, eval_prompt, role=\"user\")\n",
    "    add_messages(messages, \"```json\", role=\"assistant\")\n",
    "    eval_text = chat(messages, stop_sequences=[\"```\"])\n",
    "    return json.loads(eval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83809a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Passes a test case into Claude\n",
    "def run_prompt(test_case):\n",
    "    prompt = f\"\"\"\n",
    "Please solve the following task:\n",
    "\n",
    "{test_case[\"task\"]}\n",
    "\"\"\"\n",
    "\n",
    "    messages = []\n",
    "    add_messages(messages, prompt, role=\"user\")\n",
    "    output = chat(messages)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bcc4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to execute a single test case and grade the output\n",
    "def run_test_case(test_case):\n",
    "    \"\"\"Calls run_prompt, then grades the result\"\"\"\n",
    "    output = run_prompt(test_case)\n",
    "\n",
    "    model_grade = grade_by_model(test_case, output)\n",
    "    score = model_grade[\"score\"]\n",
    "    reasoning = model_grade[\"reasoning\"]\n",
    "\n",
    "    return {\n",
    "        \"output\": output,\n",
    "        \"test_case\": test_case,\n",
    "        \"score\": score,\n",
    "        \"reasoning\": reasoning,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fa99d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "\n",
    "\n",
    "def run_eval(dataset):\n",
    "    \"\"\"Loads the dataset and calls run_test_case with each case\"\"\"\n",
    "    results = []\n",
    "\n",
    "    for test_case in dataset:\n",
    "        result = run_test_case(test_case)\n",
    "        results.append(result)\n",
    "\n",
    "    average_score = mean([result[\"score\"] for result in results])\n",
    "    print(f\"Average score: {average_score}\")\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30fae983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average score: 7.333333333333333\n"
     ]
    }
   ],
   "source": [
    "with open(\"dataset.json\", \"r\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "results = run_eval(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc6111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"output\": \"# AWS S3 Bucket Name Parser\\n\\nHere's a solution to parse the bucket name from an S3 URI:\\n\\n```python\\ndef parse_s3_bucket_name(s3_uri: str) -> str:\\n    \\\"\\\"\\\"\\n    Extract the bucket name from an S3 URI.\\n    \\n    Args:\\n        s3_uri: S3 URI in format 's3://bucket-name/key/path'\\n        \\n    Returns:\\n        The bucket name\\n        \\n    Raises:\\n        ValueError: If the URI format is invalid\\n    \\\"\\\"\\\"\\n    if not s3_uri.startswith('s3://'):\\n        raise ValueError(\\\"S3 URI must start with 's3://'\\\")\\n    \\n    # Remove the 's3://' prefix\\n    remainder = s3_uri[5:]\\n    \\n    # Extract bucket name (everything before the first '/')\\n    bucket_name = remainder.split('/')[0]\\n    \\n    if not bucket_name:\\n        raise ValueError(\\\"Bucket name cannot be empty\\\")\\n    \\n    return bucket_name\\n\\n\\n# Test cases\\nif __name__ == \\\"__main__\\\":\\n    test_cases = [\\n        \\\"s3://my-bucket/path/to/file.txt\\\",\\n        \\\"s3://bucket-name/key/path\\\",\\n        \\\"s3://simple-bucket/\\\",\\n        \\\"s3://bucket\\\",\\n    ]\\n    \\n    for uri in test_cases:\\n        bucket = parse_s3_bucket_name(uri)\\n        print(f\\\"URI: {uri} \\u2192 Bucket: {bucket}\\\")\\n```\\n\\n**Output:**\\n```\\nURI: s3://my-bucket/path/to/file.txt \\u2192 Bucket: my-bucket\\nURI: s3://bucket-name/key/path \\u2192 Bucket: bucket-name\\nURI: s3://simple-bucket/ \\u2192 Bucket: simple-bucket\\nURI: s3://bucket \\u2192 Bucket: bucket\\n```\\n\\n## Alternative Using Regex\\n\\n```python\\nimport re\\n\\ndef parse_s3_bucket_name_regex(s3_uri: str) -> str:\\n    \\\"\\\"\\\"Parse bucket name using regex.\\\"\\\"\\\"\\n    match = re.match(r's3://([^/]+)', s3_uri)\\n    if not match:\\n        raise ValueError(\\\"Invalid S3 URI format\\\")\\n    return match.group(1)\\n```\\n\\n## Using urllib (Standard Library)\\n\\n```python\\nfrom urllib.parse import urlparse\\n\\ndef parse_s3_bucket_name_urllib(s3_uri: str) -> str:\\n    \\\"\\\"\\\"Parse bucket name using urllib.\\\"\\\"\\\"\\n    parsed = urlparse(s3_uri)\\n    if parsed.scheme != 's3':\\n        raise ValueError(\\\"S3 URI must use 's3' scheme\\\")\\n    return parsed.netloc\\n```\\n\\nAll three approaches work well. Choose based on your preference:\\n- **First approach**: Simple, no dependencies, clear logic\\n- **Regex approach**: Concise, pattern-based\\n- **urllib approach**: Uses Python standard library parsing\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Parse an AWS S3 bucket name from an S3 URI in the format 's3://bucket-name/key/path'\",\n",
      "      \"format\": \"regex\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly solves the core parsing task and offers thoughtful alternatives. The primary strength is the multi-approach presentation with trade-off analysis. However, it lacks S3-specific validation (bucket naming constraints per AWS documentation) and doesn't thoroughly verify the urllib approach works as claimed. The test cases are positive-path only and don't validate the error handling described in the docstrings. For production use, especially with AWS integration, proper bucket name validation would be essential.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# AWS Lambda Function Configuration\\n\\nHere's a JSON configuration object for an AWS Lambda function:\\n\\n```json\\n{\\n  \\\"FunctionName\\\": \\\"my-lambda-function\\\",\\n  \\\"Runtime\\\": \\\"python3.11\\\",\\n  \\\"MemorySize\\\": 256,\\n  \\\"Timeout\\\": 30,\\n  \\\"Handler\\\": \\\"index.lambda_handler\\\",\\n  \\\"Role\\\": \\\"arn:aws:iam::123456789012:role/lambda-execution-role\\\"\\n}\\n```\\n\\n## Configuration Breakdown\\n\\n| Property | Value | Description |\\n|----------|-------|-------------|\\n| **FunctionName** | `my-lambda-function` | The name of your Lambda function |\\n| **Runtime** | `python3.11` | Python 3.11 runtime environment |\\n| **MemorySize** | `256` | Memory allocation in MB (128-10,240 MB) |\\n| **Timeout** | `30` | Maximum execution time in seconds (1-900 seconds) |\\n| **Handler** | `index.lambda_handler` | Entry point for function execution |\\n| **Role** | `arn:aws:iam::...` | IAM execution role ARN |\\n\\n## Additional Optional Properties\\n\\n```json\\n{\\n  \\\"FunctionName\\\": \\\"my-lambda-function\\\",\\n  \\\"Runtime\\\": \\\"python3.11\\\",\\n  \\\"MemorySize\\\": 256,\\n  \\\"Timeout\\\": 30,\\n  \\\"Handler\\\": \\\"index.lambda_handler\\\",\\n  \\\"Role\\\": \\\"arn:aws:iam::123456789012:role/lambda-execution-role\\\",\\n  \\\"Description\\\": \\\"My Lambda function description\\\",\\n  \\\"Environment\\\": {\\n    \\\"Variables\\\": {\\n      \\\"ENV\\\": \\\"production\\\",\\n      \\\"LOG_LEVEL\\\": \\\"INFO\\\"\\n    }\\n  },\\n  \\\"VpcConfig\\\": {\\n    \\\"SubnetIds\\\": [\\\"subnet-12345678\\\"],\\n    \\\"SecurityGroupIds\\\": [\\\"sg-12345678\\\"]\\n  },\\n  \\\"Tags\\\": {\\n    \\\"Environment\\\": \\\"production\\\",\\n    \\\"Application\\\": \\\"my-app\\\"\\n  }\\n}\\n```\\n\\nThis configuration can be used with AWS CLI or SDKs to create or update Lambda functions.\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Create a JSON configuration object for an AWS Lambda function that specifies the function name, runtime (python3.11), memory (256 MB), and timeout (30 seconds)\",\n",
      "      \"format\": \"json\"\n",
      "    },\n",
      "    \"score\": 8,\n",
      "    \"reasoning\": \"The solution correctly addresses all task requirements with accurate AWS Lambda configuration syntax. The core JSON object is production-ready and properly formatted. The addition of explanatory content demonstrates good communication, though the optional properties section ventures beyond scope. Minor clarity issues around placeholder values and assumptions about handler naming prevent a perfect score.\"\n",
      "  },\n",
      "  {\n",
      "    \"output\": \"# AWS IAM Policy Action Extractor\\n\\n```python\\ndef extract_iam_policy_actions(policy_document):\\n    \\\"\\\"\\\"\\n    Extract all Action strings from an AWS IAM policy document.\\n    \\n    Args:\\n        policy_document (dict): An AWS IAM policy document as a dictionary\\n        \\n    Returns:\\n        list: A list of all Action strings granted by the policy\\n        \\n    Example:\\n        >>> policy = {\\n        ...     \\\"Version\\\": \\\"2012-10-17\\\",\\n        ...     \\\"Statement\\\": [\\n        ...         {\\n        ...             \\\"Effect\\\": \\\"Allow\\\",\\n        ...             \\\"Action\\\": [\\\"s3:GetObject\\\", \\\"s3:PutObject\\\"],\\n        ...             \\\"Resource\\\": \\\"arn:aws:s3:::my-bucket/*\\\"\\n        ...         },\\n        ...         {\\n        ...             \\\"Effect\\\": \\\"Allow\\\",\\n        ...             \\\"Action\\\": \\\"ec2:DescribeInstances\\\",\\n        ...             \\\"Resource\\\": \\\"*\\\"\\n        ...         }\\n        ...     ]\\n        ... }\\n        >>> extract_iam_policy_actions(policy)\\n        ['s3:GetObject', 's3:PutObject', 'ec2:DescribeInstances']\\n    \\\"\\\"\\\"\\n    actions = []\\n    \\n    # Check if policy_document is a valid dictionary\\n    if not isinstance(policy_document, dict):\\n        return actions\\n    \\n    # Get the Statement array from the policy\\n    statements = policy_document.get('Statement', [])\\n    \\n    # Handle case where Statement is not a list\\n    if not isinstance(statements, list):\\n        statements = [statements]\\n    \\n    # Iterate through each statement\\n    for statement in statements:\\n        if not isinstance(statement, dict):\\n            continue\\n        \\n        # Get the Action field from the statement\\n        action = statement.get('Action')\\n        \\n        if action is None:\\n            continue\\n        \\n        # Action can be a string or a list of strings\\n        if isinstance(action, str):\\n            actions.append(action)\\n        elif isinstance(action, list):\\n            actions.extend(action)\\n    \\n    return actions\\n\\n\\n# Test cases\\nif __name__ == \\\"__main__\\\":\\n    # Test 1: Policy with multiple actions in a list\\n    policy1 = {\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": [\\\"s3:GetObject\\\", \\\"s3:PutObject\\\"],\\n                \\\"Resource\\\": \\\"arn:aws:s3:::my-bucket/*\\\"\\n            },\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": \\\"ec2:DescribeInstances\\\",\\n                \\\"Resource\\\": \\\"*\\\"\\n            }\\n        ]\\n    }\\n    print(\\\"Test 1:\\\", extract_iam_policy_actions(policy1))\\n    # Expected: ['s3:GetObject', 's3:PutObject', 'ec2:DescribeInstances']\\n    \\n    # Test 2: Policy with wildcard actions\\n    policy2 = {\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": \\\"*\\\",\\n                \\\"Resource\\\": \\\"*\\\"\\n            }\\n        ]\\n    }\\n    print(\\\"Test 2:\\\", extract_iam_policy_actions(policy2))\\n    # Expected: ['*']\\n    \\n    # Test 3: Policy with multiple statements\\n    policy3 = {\\n        \\\"Version\\\": \\\"2012-10-17\\\",\\n        \\\"Statement\\\": [\\n            {\\n                \\\"Effect\\\": \\\"Allow\\\",\\n                \\\"Action\\\": [\\\"iam:GetUser\\\", \\\"iam:ListUsers\\\"],\\n                \\\"Resource\\\": \\\"*\\\"\\n            },\\n            {\\n                \\\"Effect\\\": \\\"Deny\\\",\\n                \\\"Action\\\": \\\"iam:DeleteUser\\\",\\n                \\\"Resource\\\": \\\"*\\\"\\n            }\\n        ]\\n    }\\n    print(\\\"Test 3:\\\", extract_iam_policy_actions(policy3))\\n    # Expected: ['iam:GetUser', 'iam:ListUsers', 'iam:DeleteUser']\\n    \\n    # Test 4: Empty policy\\n    policy4 = {}\\n    print(\\\"Test 4:\\\", extract_iam_policy_actions(policy\",\n",
      "    \"test_case\": {\n",
      "      \"task\": \"Write a Python function that takes an AWS IAM policy document (as a dictionary) and returns a list of all the Action strings granted by the policy\",\n",
      "      \"format\": \"python\"\n",
      "    },\n",
      "    \"score\": 7,\n",
      "    \"reasoning\": \"The solution correctly addresses the core requirement of extracting Action strings from IAM policy documents with good defensive programming. It properly handles the variability of the Action field (string vs list) and malformed input. However, the incomplete test code is a significant concern for production use. More importantly, the function misses the NotAction field which is a legitimate AWS IAM policy construct that should also be captured. The solution would fail to extract actions from policies using NotAction syntax, limiting its completeness as a policy analyzer.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(results, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
